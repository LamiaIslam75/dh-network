{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16dc89c3",
   "metadata": {},
   "source": [
    "# Analyse 1: Diachrone Frequenzdiagramme <!-- Analysis 1: Diachronic Frequencies Plots --> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d0e29",
   "metadata": {},
   "source": [
    "Jetzt werden wir die CONLL-Daten nehmen und einige Analysen durchführen. Unser erster Schritt wird sein, die Wort-/Lemma-Häufigkeiten für die Monate des Jahres 1918 zu plotten und zu sehen, ob sie mit den Wellen der Grippepandemie korrelieren.\n",
    "\n",
    "<!-- Now we'll take the CONLL data and do some analysis. Our first step would be to plot word/lemma frequencies for months of year 1918 and see if they correlate with the waves of the flu pandemic --> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a267e",
   "metadata": {},
   "source": [
    "## 0. Importe und Daten-Upload <!-- Imports and data upload --> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8dd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for interactivity in jupyter books\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import CustomJS, TextInput, Div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conllfiles = Path(r\"../data/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645fa9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_annotations = {}\n",
    "for file in conllfiles.iterdir():\n",
    "    if file.suffix == '.csv':\n",
    "        #path = os.path.join(conllfiles, filename)  \n",
    "        data = pd.read_csv(file) \n",
    "        corpus_annotations[file.name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb88bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_metadata = pd.read_csv(Path('../data/metadata/QUADRIGA_FS-Text-01_Data01_Corpus-Table.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_metadata = corpus_metadata.set_index('DC.identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d14dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Bokeh output is displayed in the notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3da39",
   "metadata": {},
   "source": [
    "## 1. Suche nach einem Lemma und plotte die Häufigkeit <!-- Search for a lemma and plot frequency -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordSearchEngine:\n",
    "    \n",
    "    def __init__(self, corpus_annotated, corpus_metadata, granularity_parameter='month'):\n",
    "        self.granularity_parameter = granularity_parameter\n",
    "        self.prepare_index_dataframe_for_search(corpus_annotated, corpus_metadata)\n",
    "    \n",
    "    def prepare_index_dataframe_for_search(self, corpus_annotated, corpus_metadata):\n",
    "        for filename, annotated_text in corpus_annotated.items():\n",
    "            txtname = filename.replace('.csv', '')\n",
    "            if txtname in corpus_metadata.index:\n",
    "                year, month, day, week = self.get_date_fname(txtname, corpus_metadata)\n",
    "                annotated_text['month'] = month\n",
    "                annotated_text['day'] = day\n",
    "                annotated_text['week'] = week\n",
    "        self.full_df = pd.concat(corpus_annotated.values())\n",
    "        self.monthly_word_counts = self.full_df.groupby(self.granularity_parameter).count().Token\n",
    "        print(f'Searching in a corpus of {self.full_df.shape[0]} word occurences')\n",
    "        \n",
    "    def get_date_fname(self, txtname, corpus_metadata):  \n",
    "        date = corpus_metadata.loc[txtname, 'DC.date']\n",
    "        date_str = str(date)\n",
    "        year = date_str[:4]\n",
    "        month = f\"{date_str[:7]}\"\n",
    "        day = date_str\n",
    "        # week\n",
    "        date_obj = pd.to_datetime(date_str)\n",
    "        week_number = f'{year}_week_{date_obj.weekofyear}'\n",
    "        return year, month, day, week_number \n",
    "        \n",
    "    def search_and_plot(self, search_terms, absolute_freqs=False):\n",
    "        search_terms = search_terms.split(',')\n",
    "        search_terms = [x.strip() for x in search_terms]\n",
    "        result = self.full_df.query(f'Lemma.isin({search_terms})')\n",
    "        if absolute_freqs:\n",
    "            absolute_freqs = result.groupby(self.granularity_parameter).count().Lemma\n",
    "            absolute_freqs.plot(title=f'frequency of {search_term}');\n",
    "            #print(absolute_freqs)\n",
    "        else:\n",
    "            #print(monthly_word_counts)\n",
    "            relative_freqs = result.groupby(self.granularity_parameter).count().Lemma/self.monthly_word_counts\n",
    "            relative_freqs = relative_freqs.fillna(0)\n",
    "            #print(relative_freqs)\n",
    "            relative_freqs.plot(title=f'frequency of {search_terms}')\n",
    "        \n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = TextInput(value='Grippe, Krankheit', \n",
    "                                 title=\"Geben Sie die zu suchenden Wörter ein und trennen Sie sie durch Kommas, wenn es mehrere sind:\") #input('Insert words to search, split by comma if more than one: ')\n",
    "\n",
    "search_terms_str = search_terms.value.strip()\n",
    "# JavaScript callback to update the in Jupyter Book\n",
    "rewrite_var_after_input = CustomJS(args=dict(text_input=search_terms), code=\"\"\"\n",
    "    var word = text_input.value.trim();\n",
    "    console.log('Input value:', word);\n",
    "    function sendToPython(){\n",
    "    var kernel = IPython.notebook.kernel;\n",
    "    kernel.execute(\"search_terms_str = '\" + word + \"'\");\n",
    "    }\n",
    "    sendToPython();\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "search_terms.js_on_change('value', rewrite_var_after_input)\n",
    "\n",
    "# Layout and display\n",
    "layout = column(search_terms)\n",
    "\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = WordSearchEngine(corpus_annotations, corpus_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.search_and_plot(search_terms_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffeb48a",
   "metadata": {},
   "source": [
    "## 3. Diskussion des Zwischenergebnisses\n",
    "\n",
    "Ist dieses Ergebnis sinnvoll und spiegelt es tatsächlich etwas wider? Eine Möglichkeit, dies zu überprüfen, besteht darin, unser Diagramm mit den tatsächlichen Daten über die Intensität der Pandemie zu vergleichen.\n",
    "\n",
    "In (Taubenberger, J. K., & Morens, D. M. (2006). 1918 Influenza: the Mother of All Pandemics. Emerging Infectious Diseases, 12(1), 15-22. https://doi.org/10.3201/eid1201.050979) wird festgestellt, dass 'The first pandemic influenza wave appeared in the spring of 1918, followed in rapid succession by much more fatal second and third waves in the fall and winter of 1918–1919, respectively'('Die erste Pandemie-Influenza-Welle im Frühjahr 1918 auftrat, gefolgt von weitaus tödlicheren zweiten und dritten Wellen im Herbst und Winter 1918–1919'). Sie ergänzen diese Aussage auch mit einem Diagramm aus einem früheren Papier (Jordan E. (1927). Epidemic influenza: a survey. Chicago: American Medical Association):\n",
    "\n",
    "<!-- ## 3. Discussion of the intermediate result \n",
    "\n",
    "Is this result meaningful and does it actually reflect something? One way to check that is to compare our plot with the actual data about the intensity of the pandemic. \n",
    "\n",
    "In (Taubenberger, J. K., & Morens, D. M. (2006). 1918 Influenza: the Mother of All Pandemics. Emerging Infectious Diseases, 12(1), 15-22. https://doi.org/10.3201/eid1201.050979) it is stated that 'The first pandemic influenza wave appeared in the spring of 1918, followed in rapid succession by much more fatal second and third waves in the fall and winter of 1918–1919, respectively'. They also supplement this statement with a plot from an earlier paper (Jordan  E. (1927). Epidemic influenza: a survey. Chicago: American Medical Association): --> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551cb63d",
   "metadata": {},
   "source": [
    "<img src=\"https://wwwnc.cdc.gov/eid/images/05-0979-F1.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ed9af",
   "metadata": {},
   "source": [
    "Unsere zwei Wellen von Erwähnungen des Wortes 'Grippe' scheinen den Sterblichkeitszahlen zu entsprechen, was darauf hindeuten könnte, dass die Methode, obwohl sehr einfach, funktioniert und dass historische Ereignisse manchmal in Wortfrequenzzählungen reflektiert werden können... Die dritte Welle scheint nicht reproduziert zu werden, was eine weitere Untersuchung erfordert. Eine Hypothese könnte sein, dass, ähnlich wie bei der COVID-Pandemie, neue Krankheitswellen irgendwann aufhören, die Aufmerksamkeit der Öffentlichkeit zu erregen. Beispielsweise waren die COVID-Wellen im Jahr 2021 stärker als die im Jahr 2020, aber die Berichterstattung in den Nachrichten nahm bereits ab. Dies könnte besonders für Anfang 1919 zutreffen, als nach dem Verlust des Krieges und der Revolution von 1918 Grippetodesfälle kein Nachrichtenthema mehr waren.\n",
    "<!-- Our two waves of mentions of the word 'Grippe' seem to correspond to the mortality figures, which could indicate that the method, albeit very simple, works and that historical events can sometimes be reflected in word frequency counts... The third wave does not seem to rerpoduce, which calls for further investigation. One hypothesis could be that, like with the COVID pandemic, at some point new waves of illness stop attracting public's attention. E.g. the 2021 covid waves were stronger than the 2020, but the news coverage was already waning. This coul be especially true for early 1919, when after the loss of the war and the 1918 revolution grippe deaths were not a news topic anymore. -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
