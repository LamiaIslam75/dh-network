{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16dc89c3",
   "metadata": {},
   "source": [
    "# Analyse 2: Keyword in Context (KWIC) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a267e",
   "metadata": {},
   "source": [
    "## 0. Importe und Daten-Upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8dd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conllfiles = Path(r\"../data/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645fa9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_annotations = {}\n",
    "for file in conllfiles.iterdir():\n",
    "    if file.suffix == '.csv':\n",
    "        #path = os.path.join(conllfiles, filename)  \n",
    "        data = pd.read_csv(file) \n",
    "        corpus_annotations[file.name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb88bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_metadata = pd.read_csv(Path('../data/metadata/QUADRIGA_FS-Text-01_Data01_Corpus-Table.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_metadata = corpus_metadata.set_index('DC.identifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a2a08b",
   "metadata": {},
   "source": [
    "## 1. KWIC-Suche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9684f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextViewer:\n",
    "    \n",
    "    def __init__(self, corpus_annotated, corpus_metadata):\n",
    "        self.prepare_index_dataframe_for_search(corpus_annotated, corpus_metadata)\n",
    "    \n",
    "    def prepare_index_dataframe_for_search(self, corpus_annotated, corpus_metadata):\n",
    "        for filename, annotated_text in corpus_annotated.items():\n",
    "            txtname = filename.replace('.csv', '')\n",
    "            if txtname in corpus_metadata.index:\n",
    "                year, month, day = self.get_date_fname(txtname, corpus_metadata)\n",
    "                annotated_text['month'] = month\n",
    "                annotated_text['filename'] = filename\n",
    "        self.full_df = pd.concat(corpus_annotated.values())\n",
    "        self.full_df = self.full_df.reset_index()\n",
    "        print(f'Searching in a corpus of {self.full_df.shape[0]} word occurences')\n",
    "        \n",
    "    def get_date_fname(self, txtname, corpus_metadata):  \n",
    "        date = corpus_metadata.loc[txtname, 'DC.date']\n",
    "        date = str(date)\n",
    "        year = date[:4]\n",
    "        month = date[:7]\n",
    "        day = date\n",
    "        return year, month, day \n",
    "    \n",
    "    def get_context_words(self, n_words):\n",
    "        search_terms = input('Insert a word to search, split by comma if more than one: ')\n",
    "        if len(search_terms) == 0:\n",
    "            search_terms = 'Grippe, Krankheit'\n",
    "        search_terms = search_terms.split(',')\n",
    "        search_terms = [x.strip() for x in search_terms]\n",
    "        indices = self.full_df.query(f'Lemma.isin({search_terms})').index\n",
    "        #print(indices)\n",
    "        left_contexts = []\n",
    "        this_words = []\n",
    "        right_contexts = []\n",
    "        months = []\n",
    "        for indice in indices:\n",
    "            left = self.full_df.iloc[indice-10:indice-1, ][\"Token\"]\n",
    "            leftс = left[~left.str.contains('\\n')]\n",
    "            right = self.full_df.iloc[indice+1:indice+10, ][\"Token\"]\n",
    "            rightс = right[~right.str.contains('\\n')]\n",
    "            left_contexts.append(' '.join(leftс))\n",
    "            right_contexts.append(' '.join(rightс))\n",
    "            this_words.append(self.full_df.iloc[indice, ][\"Token\"])\n",
    "            months.append(self.full_df.iloc[indice, ][\"month\"])\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['left_context'] = left_contexts\n",
    "        newdf['word'] = this_words\n",
    "        newdf['right_context'] = right_contexts\n",
    "        newdf['month'] = months\n",
    "        return newdf\n",
    "        \n",
    "    ## currently unused functionality:\n",
    "    def get_context_sents(self, n_sentences):\n",
    "        search_lemma = input('Insert a word to search: ')\n",
    "        if len(search_lemma) == 0:\n",
    "            search_lemma = 'Grippe'\n",
    "        indices = self.full_df.query(f'Lemma==\"{search_lemma}\"').index\n",
    "        #print(indices)\n",
    "        left_contexts = []\n",
    "        this_sentences = []\n",
    "        right_contexts = []\n",
    "        months = []\n",
    "        for indice in indices:\n",
    "            #print(indice)\n",
    "            current_filename = self.full_df.iloc[indice, ][\"filename\"]\n",
    "            current_sentence_id = self.full_df.iloc[indice, ][\"Sentence_idx\"]\n",
    "            left_context = self.get_sents(direction=-1, \n",
    "                                              current_filename=current_filename, \n",
    "                                              current_sentence_id=current_sentence_id, \n",
    "                                              n_sentences=n_sentences) \n",
    "            left_contexts.append(left_context)\n",
    "            right_context = self.get_sents(direction=1, \n",
    "                                               current_filename=current_filename, \n",
    "                                               current_sentence_id=current_sentence_id, \n",
    "                                               n_sentences=n_sentences) \n",
    "            right_contexts.append(right_context)\n",
    "            this_sentence = self.get_sents(direction=0, \n",
    "                                               current_filename=current_filename,\n",
    "                                               current_sentence_id=current_sentence_id,\n",
    "                                               n_sentences=1)\n",
    "            this_sentences.append(this_sentence)\n",
    "            #this_words.append(self.full_df.iloc[indice, ][\"Token\"])\n",
    "            months.append(self.full_df.iloc[indice, ][\"month\"])\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['left_sentences'] = left_contexts\n",
    "        newdf['this_sentence'] = this_sentences\n",
    "        newdf['right_sentences'] = right_contexts\n",
    "        newdf['month'] = months\n",
    "        return newdf #.sort_values(by='month')\n",
    "    \n",
    "    def get_sents(self, direction, current_filename, current_sentence_id, n_sentences):\n",
    "        sentences = []\n",
    "        for n in range(1,n_sentences+1):\n",
    "            sentence_id = current_sentence_id + (n * direction)\n",
    "            this_sentence = self.create_sentence(current_filename, sentence_id)\n",
    "            sentences.append(this_sentence)\n",
    "        #print(' '.join(sentences))\n",
    "        return ' '.join(sentences)\n",
    "    \n",
    "    def create_sentence(self, current_filename, sentence_id):\n",
    "        words = self.full_df.query(f'filename==\"{current_filename}\" and Sentence_idx=={sentence_id}')['Token']\n",
    "        sentence = ' '.join(words)\n",
    "        #print(sentence)\n",
    "        return sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec93d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic = ContextViewer(corpus_annotations, corpus_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic.get_context_words(n_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c6ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
