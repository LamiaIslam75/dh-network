{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16dc89c3",
   "metadata": {},
   "source": [
    "# Analysis 2: Key Word in Context (KWIC) search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a267e",
   "metadata": {},
   "source": [
    "## 0. Imports and data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14dc18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e1e86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8dd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4417616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conllfiles = Path(r\"../data/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "645fa9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_annotations = {}\n",
    "for file in conllfiles.iterdir():\n",
    "    if file.suffix == '.csv':\n",
    "        #path = os.path.join(conllfiles, filename)  \n",
    "        data = pd.read_csv(file) \n",
    "        corpus_annotations[file.name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edb88bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_metadata = pd.read_csv(Path('../data/metadata/QUADRIGA_FS-Text-01_Data01_Corpus-Table.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f3b5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_metadata = corpus_metadata.set_index('DC.identifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a2a08b",
   "metadata": {},
   "source": [
    "## 1. KWIC-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9684f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextViewer:\n",
    "    \n",
    "    def __init__(self, corpus_annotated, corpus_metadata):\n",
    "        self.prepare_index_dataframe_for_search(corpus_annotated, corpus_metadata)\n",
    "    \n",
    "    def prepare_index_dataframe_for_search(self, corpus_annotated, corpus_metadata):\n",
    "        for filename, annotated_text in corpus_annotated.items():\n",
    "            txtname = filename.replace('.csv', '')\n",
    "            if txtname in corpus_metadata.index:\n",
    "                year, month, day = self.get_date_fname(txtname, corpus_metadata)\n",
    "                annotated_text['month'] = month\n",
    "                annotated_text['filename'] = filename\n",
    "        self.full_df = pd.concat(corpus_annotated.values())\n",
    "        self.full_df = self.full_df.reset_index()\n",
    "        print(f'Searching in a corpus of {self.full_df.shape[0]} word occurences')\n",
    "        \n",
    "    def get_date_fname(self, txtname, corpus_metadata):  \n",
    "        date = corpus_metadata.loc[txtname, 'DC.date']\n",
    "        date = str(date)\n",
    "        year = date[:4]\n",
    "        month = date[:7]\n",
    "        day = date\n",
    "        return year, month, day \n",
    "    \n",
    "    def get_context_words(self, n_words):\n",
    "        search_lemma = input('Insert a word to search: ')\n",
    "        if len(search_lemma) == 0:\n",
    "            search_lemma = 'Grippe'\n",
    "        indices = self.full_df.query(f'Lemma==\"{search_lemma}\"').index\n",
    "        #print(indices)\n",
    "        left_contexts = []\n",
    "        this_words = []\n",
    "        right_contexts = []\n",
    "        months = []\n",
    "        for indice in indices:\n",
    "            left = self.full_df.iloc[indice-10:indice-1, ][\"Token\"]\n",
    "            leftс = left[~left.str.contains('\\n')]\n",
    "            right = self.full_df.iloc[indice+1:indice+10, ][\"Token\"]\n",
    "            rightс = right[~right.str.contains('\\n')]\n",
    "            left_contexts.append(' '.join(leftс))\n",
    "            right_contexts.append(' '.join(rightс))\n",
    "            this_words.append(self.full_df.iloc[indice, ][\"Token\"])\n",
    "            months.append(self.full_df.iloc[indice, ][\"month\"])\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['left_context'] = left_contexts\n",
    "        newdf['word'] = this_words\n",
    "        newdf['right_context'] = right_contexts\n",
    "        newdf['month'] = months\n",
    "        return newdf\n",
    "        \n",
    "    ## currently unused functionality:\n",
    "    def get_context_sents(self, n_sentences):\n",
    "        search_lemma = input('Insert a word to search: ')\n",
    "        if len(search_lemma) == 0:\n",
    "            search_lemma = 'Grippe'\n",
    "        indices = self.full_df.query(f'Lemma==\"{search_lemma}\"').index\n",
    "        #print(indices)\n",
    "        left_contexts = []\n",
    "        this_sentences = []\n",
    "        right_contexts = []\n",
    "        months = []\n",
    "        for indice in indices:\n",
    "            #print(indice)\n",
    "            current_filename = self.full_df.iloc[indice, ][\"filename\"]\n",
    "            current_sentence_id = self.full_df.iloc[indice, ][\"Sentence_idx\"]\n",
    "            left_context = self.get_sents(direction=-1, \n",
    "                                              current_filename=current_filename, \n",
    "                                              current_sentence_id=current_sentence_id, \n",
    "                                              n_sentences=n_sentences) \n",
    "            left_contexts.append(left_context)\n",
    "            right_context = self.get_sents(direction=1, \n",
    "                                               current_filename=current_filename, \n",
    "                                               current_sentence_id=current_sentence_id, \n",
    "                                               n_sentences=n_sentences) \n",
    "            right_contexts.append(right_context)\n",
    "            this_sentence = self.get_sents(direction=0, \n",
    "                                               current_filename=current_filename,\n",
    "                                               current_sentence_id=current_sentence_id,\n",
    "                                               n_sentences=1)\n",
    "            this_sentences.append(this_sentence)\n",
    "            #this_words.append(self.full_df.iloc[indice, ][\"Token\"])\n",
    "            months.append(self.full_df.iloc[indice, ][\"month\"])\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['left_sentences'] = left_contexts\n",
    "        newdf['this_sentence'] = this_sentences\n",
    "        newdf['right_sentences'] = right_contexts\n",
    "        newdf['month'] = months\n",
    "        return newdf #.sort_values(by='month')\n",
    "    \n",
    "    def get_sents(self, direction, current_filename, current_sentence_id, n_sentences):\n",
    "        sentences = []\n",
    "        for n in range(1,n_sentences+1):\n",
    "            sentence_id = current_sentence_id + (n * direction)\n",
    "            this_sentence = self.create_sentence(current_filename, sentence_id)\n",
    "            sentences.append(this_sentence)\n",
    "        #print(' '.join(sentences))\n",
    "        return ' '.join(sentences)\n",
    "    \n",
    "    def create_sentence(self, current_filename, sentence_id):\n",
    "        words = self.full_df.query(f'filename==\"{current_filename}\" and Sentence_idx=={sentence_id}')['Token']\n",
    "        sentence = ' '.join(words)\n",
    "        #print(sentence)\n",
    "        return sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ec93d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching in a corpus of 33165791 word occurences\n"
     ]
    }
   ],
   "source": [
    "kwic = ContextViewer(corpus_annotations, corpus_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82e2f1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a word to search: Grippe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_context</th>\n",
       "      <th>word</th>\n",
       "      <th>right_context</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>. 3. verschied in einem Feld- 8 lazarett infolge</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>im 32 , Lebensjahre unser Wi   Prokurfft Sert</td>\n",
       "      <td>1918-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rachricht von dem am 19. Oltober d. I. infolge</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>erfolgten Hin- scheidens unseres Prokuristen ,...</td>\n",
       "      <td>1918-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elfe , geb. Freudenthal .   Infolge Erkrankung «</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>mit Lungenentzündung Jam nat kurzem , aber sch...</td>\n",
       "      <td>1918-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kräftsensteges entichlief heute nacht 3 Uhr an...</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>meine unvergeß » Tiche , herzensgute Geywieger...</td>\n",
       "      <td>1918-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nicht sterbenz es ist kein Muß , daß man</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>oder Typhus stirbt , unsere Heilkunde ist noch...</td>\n",
       "      <td>1919-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>einem Feldlazarett | im Felde infolge Anste &gt; ung</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>in „ treuen Pfichtersülung fürs   | Vaterland der</td>\n",
       "      <td>1918-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>ver fiel der polizeilichen Auflösung   Zur „ B...</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>hat der Gemeinderat der Stadt Beru alle öffent...</td>\n",
       "      <td>1918-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>chte Über änftige Erfolge , die mit einem Heil...</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>gemacht worden find , müssen mit Bore fit ausg...</td>\n",
       "      <td>1918-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>letzten Tegen lessen Übrigens die Anna ) els ob</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>ihren Höhepunkt über- schritten dat .   2 ;</td>\n",
       "      <td>1918-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Grippefälle und 45 Lungenentziadungen , Es fin...</td>\n",
       "      <td>Grippe</td>\n",
       "      <td>und 9 an Lungen-   und Ariminoiwaßhimeister Pr...</td>\n",
       "      <td>1918-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          left_context    word  \\\n",
       "0     . 3. verschied in einem Feld- 8 lazarett infolge  Grippe   \n",
       "1       Rachricht von dem am 19. Oltober d. I. infolge  Grippe   \n",
       "2     Elfe , geb. Freudenthal .   Infolge Erkrankung «  Grippe   \n",
       "3    Kräftsensteges entichlief heute nacht 3 Uhr an...  Grippe   \n",
       "4             nicht sterbenz es ist kein Muß , daß man  Grippe   \n",
       "..                                                 ...     ...   \n",
       "374  einem Feldlazarett | im Felde infolge Anste > ung  Grippe   \n",
       "375  ver fiel der polizeilichen Auflösung   Zur „ B...  Grippe   \n",
       "376  chte Über änftige Erfolge , die mit einem Heil...  Grippe   \n",
       "377    letzten Tegen lessen Übrigens die Anna ) els ob  Grippe   \n",
       "378  Grippefälle und 45 Lungenentziadungen , Es fin...  Grippe   \n",
       "\n",
       "                                         right_context    month  \n",
       "0        im 32 , Lebensjahre unser Wi   Prokurfft Sert  1918-10  \n",
       "1    erfolgten Hin- scheidens unseres Prokuristen ,...  1918-10  \n",
       "2    mit Lungenentzündung Jam nat kurzem , aber sch...  1918-10  \n",
       "3    meine unvergeß » Tiche , herzensgute Geywieger...  1918-10  \n",
       "4    oder Typhus stirbt , unsere Heilkunde ist noch...  1919-09  \n",
       "..                                                 ...      ...  \n",
       "374  in „ treuen Pfichtersülung fürs   | Vaterland der  1918-09  \n",
       "375  hat der Gemeinderat der Stadt Beru alle öffent...  1918-07  \n",
       "376  gemacht worden find , müssen mit Bore fit ausg...  1918-10  \n",
       "377        ihren Höhepunkt über- schritten dat .   2 ;  1918-10  \n",
       "378  und 9 an Lungen-   und Ariminoiwaßhimeister Pr...  1918-10  \n",
       "\n",
       "[379 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwic.get_context_words(n_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82cd444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
