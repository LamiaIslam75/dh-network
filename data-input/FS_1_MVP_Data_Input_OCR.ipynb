{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d59fe07",
   "metadata": {},
   "source": [
    "# Data Input\n",
    "\n",
    "## 1. Types of input data for text corpora\n",
    "\n",
    "Textual data might come in different forms. \n",
    "\n",
    "1. It could be **plain text**:\n",
    "\n",
    "```\n",
    "Die Grippe wütet weiter\n",
    "Zunahme der schweren Fälle in Berlin. Die Zahl der Grippefälle ist in den letzten beiden Tagen auch in Groß-Berlin noch deutlich gestiegen. Die Warenhäuser und sonstigen Geschäfte, die Kriegs- und die privaten Betriebe klagen, dass übermäßig viele Angestellte krank melden müssen, und auch bei der Post und bei der Straßenbahn ist die Zahl der Grippekranken bedeutend gestiegen.\n",
    "```\n",
    "\n",
    "2. It could be **images** (pdf, jpg, etc):\n",
    "\n",
    "<img src=\"grippe.png\" width=700>\n",
    "\n",
    "(source: Berliner Morgenpost, October 15, 1918)\n",
    "\n",
    "3. It could be some **structured markup** (XML/HTML):\n",
    "\n",
    "```\n",
    "<text>\n",
    "    <head>\n",
    "        Die Grippe wütet weiter\n",
    "    </head>\n",
    "    <p>\n",
    "        <s>Zunahme der schweren Fälle in Berlin.</s> \n",
    "        <s>Die Zahl der Grippefälle ist in den letzten beiden Tagen auch in Groß-Berlin noch deutlich gestiegen.</s>\n",
    "        <s>Die Warenhäuser und sonstigen Geschäfte, die Kriegs- und die privaten Betriebe klagen, dass übermäßig viele Angestellte krank melden müssen, und auch bei der Post und bei der Straßenbahn ist die Zahl der Grippekranken bedeutend gestiegen.</s>\n",
    "    </p>\n",
    "</text>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aaad4b",
   "metadata": {},
   "source": [
    "#### We have to be able to use all these formats and homogenise different sources into a unified corpus. \n",
    "\n",
    "In most cases, working with plain text is the simplest option (though sometimes you might actually want to *keep* structured XML/HTML markup and rely on that structure in your analysis). So we will convert everything to plain text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ff2e7",
   "metadata": {},
   "source": [
    "<img src=\"homogenisationchart.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29466219",
   "metadata": {},
   "source": [
    "## 2.  Images into digial text. OCR\n",
    "\n",
    "To process images into digital text we need an **Optical Character Recognition (OCR)** tool. \n",
    "\n",
    "### 2.1. How OCR works\n",
    "\n",
    "![](grippeocr.gif)\n",
    "\n",
    "A modern Optical Character Recognition (OCR) algorithm typically involves several stages. Here’s a breakdown of the key stages:\n",
    "\n",
    "1. **Preprocessing**: This initial step involves preparing the image for analysis and recognition. Common preprocessing tasks include:\n",
    "   - **Noise Reduction**: Removing noise from the image to enhance the text's clarity. This could involve filtering techniques like Gaussian blur or median filter.\n",
    "   - **Binarization**: Converting the image from grayscale or color to black-and-white, where text is typically represented as black pixels on a white background. This helps in distinguishing the text from the background.\n",
    "   - **Normalization**: Standardizing the brightness and contrast of the image to reduce variability between different images.\n",
    "   - **Dewarping**: Correcting any image distortions that result from curved surfaces or skewed scanning angles.\n",
    "\n",
    "2. **Segmentation**: This step divides the image into parts that are easier to analyze. Segmentation levels can vary based on the complexity of the layout and the requirements of the application:\n",
    "   - **Page Segmentation**: Identifying different blocks of text, images, or other elements on a page.\n",
    "   - **Line Segmentation**: Breaking down text blocks into individual lines.\n",
    "   - **Word Segmentation**: Further dividing lines into words.\n",
    "   - **Character Segmentation**: The final step where words are broken down into individual characters.\n",
    "\n",
    "3. **Feature Extraction**: In this stage, the algorithm extracts features from the segmented characters that are useful for recognition. This might include the basic shape, line endpoints, intersections, and other geometrical and topological characteristics.\n",
    "\n",
    "4. **Character Recognition**: At this stage, each character image is analyzed and compared against a pre-trained model to identify the most likely corresponding textual character. Techniques used in this stage can vary:\n",
    "   - **Pattern Recognition**: Using methods such as support vector machines or neural networks to recognize characters based on the features extracted.\n",
    "   - **Template Matching**: Comparing character images to a set of predefined character templates to find the best match.\n",
    "\n",
    "5. **Post-processing**: After characters are recognized, the algorithm performs corrections based on context and additional information:\n",
    "   - **Spell Checking and Correction**: Identifying and correcting misspelled words using dictionaries and context-based algorithms.\n",
    "   - **Language and Grammar Analysis**: Applying language-specific rules to improve the accuracy of the output text.\n",
    "\n",
    "6. **Output Formatting**: The final text is formatted according to the desired output specifications, which may include maintaining the layout, fonts, and style of the original text.\n",
    "\n",
    "Each of these stages can be enhanced by deep learning techniques, especially convolutional neural networks (CNNs) and recurrent neural networks (RNNs), which can learn to handle many of the tasks automatically and often provide better accuracy than traditional methods, especially in complex or noisy environments.\n",
    "\n",
    "### 2.2. How one performs OCR \n",
    "\n",
    "OCR technology is increasingly being integrated into basic software applications, such as PDF viewers. Tools like MacOS 'Preview' or Adobe Acrobat feature built-in OCR. But this is not suitable for bulk processing of corpora. Therefore one still needs specialized OCR software or programming packages to process large quantities of images into machine-readable corpora.  \n",
    "\n",
    "### 2.2.1. What OCR tools there are\n",
    "\n",
    "The field of making OCR tools is developing rapidly (together with all other fields of text processing), so there are always new tools challenging the old ones. But as of 2024, the well-known products were: \n",
    "\n",
    "* FineReader (commercial, has a desktop interface)\n",
    "* Tesseract (open source, command-line interface, also some third-party desktop interfaces)\n",
    "* OCR4all (open source, has a (dockerized locally deployable) desktop interface)\n",
    "* Kraken & e-Scriptorium (open source, e-Scriptorium has a desktop interface)\n",
    "* EasyOCR (open source, has a desktop interface)\n",
    "\n",
    "### 2.2.2. Performing OCR with Tesseract\n",
    "\n",
    "We'll use Tesseract in this tutorial, which is an open & free tool. Specifically, we'll use the Python package PyTesseract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af423bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytesseract\n",
    "#!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a636708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d785e48",
   "metadata": {},
   "source": [
    "This is how we can perform OCR on the image of a newspaper article ('*Die Grippe wütet weiter*') that you have already seen above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3dcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_output = pytesseract.image_to_string(Image.open('grippe.png'), lang='frk') \n",
    "print(ocr_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0cec43",
   "metadata": {},
   "source": [
    "With a bit more Python code, we can also use pytesseract to process entire PDF files with many pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74682bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a27afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pdf_path = Path('../data/pdf/SNP27112366-19181224-0-0-0-0.pdf')\n",
    "recognized_pages = []\n",
    "converted_pdf = tqdm(convert_from_path(sample_pdf_path, use_cropbox=True))\n",
    "for image in converted_pdf:\n",
    "    recognized = pytesseract.image_to_string(image, \n",
    "                                             lang='frk') \n",
    "    #print(recognized)\n",
    "    recognized_pages.append(recognized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ccdf2",
   "metadata": {},
   "source": [
    "first page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fafb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recognized_pages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b5b14",
   "metadata": {},
   "source": [
    "Last page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recognized_pages[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a1436f",
   "metadata": {},
   "source": [
    "None of these results look very good (mostly due to scan quality and general challenges of working with old newspapers). In the next parts we will learn how to \n",
    "* a) measure the OCR quality\n",
    "* b) improve the quality at the OCR postcorrection stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c60c71",
   "metadata": {},
   "source": [
    "#### P.S.Processing the whole corpus of PDF-s with the same OCR engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdce094",
   "metadata": {},
   "source": [
    "The code below will process all the files in folder `'../data/pdf'` which have '.pdf' as extension, and then put the results into the `'../data/txt'` (the filenames will be the same but with '.txt' extension instead of '.pdf'). For a large (>5) number of PDF-s this will take a long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91568303",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathpdf = Path('../data/pdf')\n",
    "pathtxt = Path('../data/txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a69f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(pathpdf.iterdir()):\n",
    "    if filename.suffix == '.pdf':\n",
    "        converted_pdf = convert_from_path(filename, use_cropbox=True)\n",
    "        output_path = pathtxt / filename.stem \n",
    "        output_path = output_path.with_suffix('.txt')\n",
    "        with output_path.open('w') as output_txt:\n",
    "            for image in converted_pdf:\n",
    "                recognized = pytesseract.image_to_string(image, \n",
    "                                                         lang='frk') \n",
    "                output_txt.write(recognized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
